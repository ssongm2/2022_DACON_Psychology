{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "db65beaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np \n",
    "\n",
    "from sklearn.impute import KNNImputer\n",
    "\n",
    "\n",
    "from string import ascii_lowercase\n",
    "from itertools import combinations\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.ensemble import  GradientBoostingClassifier\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a6ab2780",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data Load\n",
    "train = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "submission = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea6c5033",
   "metadata": {},
   "source": [
    "# Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "73aaf9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Answers = []\n",
    "for i in range(1, 27):\n",
    "    Answers.append('Q' + str(i))\n",
    "    \n",
    "Q_Answers = []\n",
    "for i in range(1, 21):\n",
    "    Q_Answers.append('Q' + str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4ed56ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def knull(col):\n",
    "    imputer = KNNImputer(n_neighbors=3)\n",
    "    a = imputer.fit_transform(train[col])\n",
    "    train[col] = a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "1402954c",
   "metadata": {},
   "outputs": [],
   "source": [
    "knull(Answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "a9c15082",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test data의 결측치 train의 최빈값으로 채우기\n",
    "for i in range(len(Answers)):\n",
    "    test[Answers[i]]=test[Answers[i]].fillna(train[Answers[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "81e41ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1~20번 항목 더해서 Q_score, 21~26번 항목 더해서 Qs_score 생성\n",
    "Q_secret= ['Q21', 'Q22', 'Q23', 'Q24', 'Q25', 'Q26']\n",
    "\n",
    "dataset = [train, test]\n",
    "\n",
    "for data in dataset:\n",
    "    data['Q_score'] = data[Q_Answers].sum(axis=1)\n",
    "    data['Qs_score'] = data[Q_secret].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ae3d1a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마키아벨리즘 테스트(1~20번 항목)에서 T, V, M 컬럼 생성\n",
    "for data in dataset:\n",
    "    data['T'] = data['Q1']+data['Q2']+data['Q3']+data['Q7']+data['Q10']+data['Q12']+data['Q15']+data['Q16'] \n",
    "    data['V'] = data['Q4']+data['Q5']+data['Q8']+data['Q11']+data['Q13']+data['Q20']\n",
    "    data['M'] = data['Q9']+data['Q19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5f09bd3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마키아벨리즘 스코어, 분산 피처 생성\n",
    "for data in dataset:\n",
    "    data['Mach_score'] = data[Answers].mean(axis = 1)\n",
    "    data['Mach_var'] = data[Answers].var(axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "c140c19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\thdal\\AppData\\Local\\Temp/ipykernel_25216/4282676114.py:5: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  data['mach_%s_dv%s'%(a,b)] = data[a]/data[b]\n"
     ]
    }
   ],
   "source": [
    "# 마키아벨리즘 비율 피처 생성\n",
    "Ancoms = list(combinations(Answers, 2))\n",
    "for data in dataset:\n",
    "    for a,b in Ancoms:\n",
    "        data['mach_%s_dv%s'%(a,b)] = data[a]/data[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "08f8a292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q drop\n",
    "for data in dataset:\n",
    "    data.drop([('Q'+str(i) )for i in range(1,27)], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4d2e146",
   "metadata": {},
   "source": [
    "# TIPI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5974f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "TIPI = []\n",
    "for i in range(1,11):\n",
    "    TIPI.append('TIPI'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "37734a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "knull(TIPI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "623539c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(TIPI)):\n",
    "    test[TIPI[i]] = test[TIPI[i]].fillna(train[TIPI[i]].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "70aba1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp1~10 항목 사용해 Ex, Ag, Con, Es, Op 컬럼 만들기\n",
    "\n",
    "train['Extraverted'] = train['TIPI1'] - train['TIPI6']\n",
    "train['Warm'] = train['TIPI7']-train['TIPI2']\n",
    "train['Dependable'] = train['TIPI3']-train['TIPI8']\n",
    "train['Calm'] = train['TIPI9']-train['TIPI4']\n",
    "train['OpenMind'] = train['TIPI5']-train['TIPI10']\n",
    "\n",
    "test['Extraverted'] = test['TIPI1'] - test['TIPI6']\n",
    "test['Warm'] = test['TIPI7']-test['TIPI2']\n",
    "test['Dependable'] = test['TIPI3']-test['TIPI8']\n",
    "test['Calm'] = test['TIPI9']-test['TIPI4']\n",
    "test['OpenMind'] = test['TIPI5']-test['TIPI10']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "dc3eb577",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tp 비율 피처 생성\n",
    "tpcoms = list(combinations(TIPI, 2))\n",
    "\n",
    "for data in dataset:\n",
    "    for a,b in tpcoms:\n",
    "        data['%s_dv_%s'%(a,b)] = data[a]/data[b]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "d6761894",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop([('TIPI'+str(i)) for i in range(1,10)], axis=1, inplace = True)\n",
    "train.drop('TIPI10', axis = 1, inplace = True)\n",
    "\n",
    "test.drop([('TIPI'+str(i)) for i in range(1,10)], axis=1, inplace = True)\n",
    "test.drop('TIPI10', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f309e855",
   "metadata": {},
   "outputs": [],
   "source": [
    "#index drop\n",
    "for data in dataset:\n",
    "    data.drop('index', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc0c75",
   "metadata": {},
   "source": [
    "# Country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "25275718",
   "metadata": {},
   "outputs": [],
   "source": [
    "def country_label(data):\n",
    "    nara = data['country'].copy()\n",
    "    nara_val = nara.value_counts()\n",
    "    \n",
    "    a = [] \n",
    "    b = []\n",
    "    c = [] \n",
    "    d = []\n",
    "    e = []\n",
    "\n",
    "    \n",
    "    for i in range(len(nara_val)):\n",
    "        if nara_val.values[i] <= 10 : a.append(nara_val.index[i])\n",
    "        elif 100>nara_val.values[i] >10 : b.append(nara_val.index[i])\n",
    "        elif 500>nara_val.values[i] >= 100 :c.append(nara_val.index[i])\n",
    "        elif 5000>nara_val.values[i] >= 500 :  d.append(nara_val.index[i])\n",
    "        elif nara_val.values[i] >= 5000 : e.append(nara_val.index[i])\n",
    "\n",
    "    for i in range(len(nara)):\n",
    "        if nara[i] in a: nara[i]=0\n",
    "        if nara[i] in b: nara[i]=1\n",
    "        if nara[i] in c: nara[i]=2\n",
    "        if nara[i] in d: nara[i]=3\n",
    "        if nara[i] in e: nara[i]=4\n",
    "\n",
    "        \n",
    "    nara.fillna(0, inplace = True)\n",
    "    return nara"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "31a087f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train['nara'] = country_label(train)\n",
    "test['nara'] = country_label(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "103effbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(columns=['country'], axis=1)\n",
    "test = test.drop(columns=['country'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e35c47",
   "metadata": {},
   "source": [
    "# VCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b15e13c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "VCL = []\n",
    "for i in range(1,17):\n",
    "    VCL.append('VCL'+str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5055f38f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#작성자의 영어 실력\n",
    "\n",
    "# 실제로 있고 진짜 쉬운단어\n",
    "VCL_1 = ['VCL1','VCL4','VCL5','VCL10','VCL14','VCL16']\n",
    "# 실제로 있는데 어려운 단어\n",
    "VCL_2 = ['VCL2','VCL3','VCL7','VCL8','VCL11','VCL13','VCL14']\n",
    "# 세상에 없는 단어\n",
    "VCL_3 = ['VCL6','VCL9','VCL12']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "07c4aa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = [train,test]\n",
    "for data in dataset:\n",
    "    data['VCL_score'] = data[VCL].sum(axis=1)\n",
    "    data['VCL_1_score'] = data[VCL_1].sum(axis=1)\n",
    "    data['VCL_2_score'] = data[VCL_2].sum(axis=1)\n",
    "    data['VCL_3_score'] = data[VCL_3].sum(axis=1)\n",
    "    data.drop([('VCL'+str(i) )for i in range(1,17)], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211f8fce",
   "metadata": {},
   "source": [
    "# Hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52812ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('hand', axis=1, inplace = True)\n",
    "test.drop('hand', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a188e8a",
   "metadata": {},
   "source": [
    "# Familysize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "51aca3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "train = train.drop(train[train.familysize > 50].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef0ef30",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ba9df49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이상치 제거\n",
    "train = train.drop(train[train.age > 100].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "1ff72f8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# age로 연령대 구간 나누기\n",
    "def age_categorize(age):\n",
    "    age = (age // 10)\n",
    "    return age\n",
    "\n",
    "train['age_cuts'] = age_categorize(train['age'])\n",
    "test['age_cuts'] = age_categorize(test['age'])\n",
    "\n",
    "# 기존의 age drop하기\n",
    "train.drop('age', axis=1, inplace=True)\n",
    "test.drop('age', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "34fedb73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        2\n",
       "1        4\n",
       "2        4\n",
       "3        1\n",
       "4        1\n",
       "        ..\n",
       "14995    1\n",
       "14996    4\n",
       "14997    2\n",
       "14998    2\n",
       "14999    2\n",
       "Name: age_cuts, Length: 14993, dtype: int64"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['age_cuts']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39ad5f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        1\n",
       "1        3\n",
       "2        1\n",
       "3        2\n",
       "4        1\n",
       "        ..\n",
       "35447    1\n",
       "35448    1\n",
       "35449    3\n",
       "35450    1\n",
       "35451    1\n",
       "Name: age_cuts, Length: 35452, dtype: int64"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['age_cuts']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8cd8a7",
   "metadata": {},
   "source": [
    "# train 결측치 대체: KNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e97bcf68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train 데이터 결측치 대체: KNN\n",
    "knull(['familysize','religion','orientation','married','voted','nerdiness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a05e67",
   "metadata": {},
   "source": [
    "# elapse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "97fe19a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "elapse = ['introelapse', 'testelapse', 'surveyelapse']\n",
    "train[elapse]=np.log1p(train[elapse])\n",
    "\n",
    "#걸린시간 합\n",
    "train['elapse_sum'] = train['testelapse']+train['surveyelapse']\n",
    "test['elapse_sum'] = test['testelapse']+test['surveyelapse']\n",
    "\n",
    "train.drop('introelapse', axis=1, inplace = True)\n",
    "test.drop('introelapse', axis=1, inplace = True)\n",
    "\n",
    "train.drop('testelapse', axis=1, inplace = True)\n",
    "test.drop('testelapse', axis=1, inplace = True)\n",
    "\n",
    "train.drop('surveyelapse', axis=1, inplace = True)\n",
    "test.drop('surveyelapse', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848228bb",
   "metadata": {},
   "source": [
    "# train, test 결측치 대체: train의 최빈값"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "9f537ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ASD 결측치 최빈값 대체\n",
    "train['ASD'] = train['ASD'].fillna(train['ASD'].mode()[0])\n",
    "test['ASD'] = test['ASD'].fillna(train['ASD'].mode()[0])\n",
    "\n",
    "#education 결측치 최빈값 대체\n",
    "train['education'] = train['education'].fillna(train['education'].mode()[0])\n",
    "test['education'] = test['education'].fillna(train['education'].mode()[0])\n",
    "\n",
    "#engnat 결측치 최빈값 대체\n",
    "train['engnat'] = train['engnat'].fillna(train['engnat'].mode()[0])\n",
    "test['engnat'] = test['engnat'].fillna(train['engnat'].mode()[0])\n",
    "\n",
    "#gender 결측치 최빈값 대체\n",
    "train['gender'] = train['gender'].fillna(train['gender'].mode()[0])\n",
    "test['gender'] = test['gender'].fillna(train['gender'].mode()[0])\n",
    "\n",
    "#religion 결측치 최빈값 대체\n",
    "test['religion'] = test['religion'].fillna(train['religion'].mode()[0])\n",
    "\n",
    "#orientation 결측치 최빈값 대체\n",
    "test['orientation'] = test['orientation'].fillna(train['orientation'].mode()[0])\n",
    "\n",
    "#voted 결측치 최빈값 대체\n",
    "test['voted'] = test['voted'].fillna(train['voted'].mode()[0])\n",
    "\n",
    "#married 결측치 최빈값 대체\n",
    "test['married'] = test['married'].fillna(train['married'].mode()[0])\n",
    "\n",
    "#familysize 결측치 최빈값 대체\n",
    "test['familysize'] = test['familysize'].fillna(train['familysize'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "b62e1723",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "encoder = LabelEncoder()\n",
    "needenco = ['gender', 'religion', 'orientation']\n",
    "for i in needenco:\n",
    "    train[i] = encoder.fit_transform(train[i])\n",
    "    test[i] = encoder.transform(test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fed21ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education      0\n",
       "urban          0\n",
       "gender         0\n",
       "engnat         0\n",
       "religion       0\n",
       "              ..\n",
       "VCL_1_score    0\n",
       "VCL_2_score    0\n",
       "VCL_3_score    0\n",
       "age_cuts       0\n",
       "elapse_sum     0\n",
       "Length: 400, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "7f05c691",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "education      0\n",
       "urban          0\n",
       "gender         0\n",
       "engnat         0\n",
       "religion       0\n",
       "              ..\n",
       "VCL_1_score    0\n",
       "VCL_2_score    0\n",
       "VCL_3_score    0\n",
       "age_cuts       0\n",
       "elapse_sum     0\n",
       "Length: 399, dtype: int64"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce08c4bc",
   "metadata": {},
   "source": [
    "# Model1: ExtraTreesRegressor + Tune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0cd7e225",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train.copy()\n",
    "train_x.drop('nerdiness', axis=1, inplace = True)\n",
    "train_y = train['nerdiness']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "a16289ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators = int(391.707369561944)\n",
    "max_depth = int(65.33353663762796)\n",
    "min_samples_split = int(5.797880430957836)\n",
    "min_samples_leaf = int(3.813420188476544)\n",
    "bootstrap = bootstrap = 0\n",
    "    \n",
    "assert type(n_estimators) == int\n",
    "assert type(max_depth) == int\n",
    "assert type(min_samples_split) == int\n",
    "assert type(min_samples_leaf) == int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e628bf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extra Trees Regressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "\n",
    "xtree_tune = ExtraTreesRegressor(n_estimators=n_estimators,\n",
    "                               max_depth=max_depth,\n",
    "                               min_samples_split=min_samples_split,\n",
    "                               min_samples_leaf=min_samples_leaf,\n",
    "                               #max_features=max_features,\n",
    "                               bootstrap=bootstrap,\n",
    "                               oob_score=bootstrap,\n",
    "                               n_jobs=6,\n",
    "                               random_state=42,\n",
    "                               verbose=0)\n",
    "\n",
    "xtree_tune.fit(train_x, train_y)\n",
    "preds_tune = xtree_tune.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "512fa075",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.16504689, 0.82630009, 0.88022165, ..., 0.96351236, 0.10741688,\n",
       "       0.66389599])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_tune"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e0b2e89",
   "metadata": {},
   "source": [
    "# Model2: LGBM 4개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d65dd71e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features, target split\n",
    "train_x = train.copy()\n",
    "train_x.drop('nerdiness', axis=1, inplace = True)\n",
    "train_y = train['nerdiness']\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1a740fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_30(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=30)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e12f78a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(action='ignore')\n",
    "#warnings.filterwarnings(action='default')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "2af2954e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 0.8511013639499383\n",
      "359 0.8515813319789425\n",
      "323 0.8467658159110986\n",
      "290 0.845912123525977\n",
      "261 0.8540828090251265\n",
      "234 0.847330433370533\n",
      "210 0.8474530886676871\n",
      "189 0.848031526442294\n",
      "170 0.8491241951106029\n",
      "153 0.8488305134131917\n",
      "137 0.843926316989659\n",
      "123 0.8503968157993843\n",
      "110 0.8410067754095132\n",
      "99 0.8449481565427099\n",
      "89 0.8492497296400844\n",
      "80 0.8438978125896162\n",
      "72 0.8449760850962873\n",
      "64 0.849699753652882\n",
      "57 0.8428854745032461\n",
      "51 0.8451554612702943\n",
      "45 0.8487435605968995\n",
      "40 0.8428425739415654\n"
     ]
    }
   ],
   "source": [
    "lgbm_30 = lgbm_rfe_30(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "439c2586",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_1 = train_x[lgbm_30.iloc[7,2]]\n",
    "model1.fit(x_train_1, train_y)\n",
    "\n",
    "pred_y1 = model1.predict_proba(test[lgbm_30.iloc[7,2]])\n",
    "pred_y1 = pred_y1[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "468f8385",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_500(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=500)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "ce526a8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 0.8439497910655255\n",
      "359 0.8463794698063993\n",
      "323 0.8447571822308129\n",
      "290 0.8405022856357692\n",
      "261 0.8419614784639882\n",
      "234 0.8484191644699391\n",
      "210 0.8409615488978258\n",
      "189 0.8434097020879591\n",
      "170 0.845312570361672\n",
      "153 0.8435765494578328\n",
      "137 0.8413388317912941\n",
      "123 0.8475341228851085\n",
      "110 0.8455103047014009\n",
      "99 0.8401610856510108\n",
      "89 0.8405268220136919\n",
      "80 0.8417394964096063\n",
      "72 0.84127994448428\n",
      "64 0.8451099287463585\n",
      "57 0.8370002228480443\n",
      "51 0.8427350960267234\n",
      "45 0.844510952461778\n",
      "40 0.8405242240442647\n"
     ]
    }
   ],
   "source": [
    "lgbm_500 = lgbm_rfe_500(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "cbfa9c0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_2 = train_x[lgbm_500.iloc[14,2]]\n",
    "model2.fit(x_train_2, train_y)\n",
    "\n",
    "pred_y2 = model2.predict_proba(test[lgbm_500.iloc[14,2]])\n",
    "pred_y2 = pred_y2[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "98ee0465",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_913(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=913)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "09fd3ee4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 0.8539730457785306\n",
      "359 0.8588248980152668\n",
      "323 0.8568700703530121\n",
      "290 0.8596940631202652\n",
      "261 0.851089588377724\n",
      "234 0.8555589617821379\n",
      "210 0.8498647901244831\n",
      "189 0.84890152079357\n",
      "170 0.8538901994201332\n",
      "153 0.8570626087538868\n",
      "137 0.8533772447899167\n",
      "123 0.8479985820860193\n",
      "110 0.8504779109092777\n",
      "99 0.8482026670176812\n",
      "89 0.8444494671853369\n",
      "80 0.8490406564895545\n",
      "72 0.8465933692892302\n",
      "64 0.8414898026813354\n",
      "57 0.8484962375629431\n",
      "51 0.8479526846261407\n",
      "45 0.842712002965149\n",
      "40 0.8519567328398345\n"
     ]
    }
   ],
   "source": [
    "lgbm_913 = lgbm_rfe_913(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "2ab84267",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_3 = train_x[lgbm_913.iloc[7,2]]\n",
    "model3.fit(x_train_3, train_y)\n",
    "\n",
    "pred_y3 = model3.predict_proba(test[lgbm_913.iloc[7,2]])\n",
    "pred_y3 = pred_y3[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "c2e01bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgbm_rfe_8(data_x, data_y, ratio=0.9, min_feats=40):\n",
    "    feats = data_x.columns.tolist()\n",
    "    archive = pd.DataFrame(columns=['model', 'n_feats', 'feats', 'score'])\n",
    "    while True:\n",
    "        model = LGBMClassifier(objective = 'binary', num_iterations=10**4)\n",
    "        x_train, x_val, y_train, y_val = train_test_split(data_x[feats], data_y, random_state=8)\n",
    "        model.fit(x_train, y_train, eval_set = [(x_val, y_val)], early_stopping_rounds=100, verbose=False)\n",
    "        val_pred = model.predict_proba(x_val)\n",
    "        val_pred = val_pred[:,1]\n",
    "        score = roc_auc_score(y_val, val_pred)\n",
    "        n_feats = len(feats)\n",
    "        print(n_feats, score)\n",
    "        archive = archive.append({'model':model, 'n_feats':n_feats, 'feats':feats, 'score':score}, ignore_index=True)\n",
    "        feat_imp = pd.Series(model.feature_importances_, index=feats).sort_values(ascending=False)\n",
    "        next_n_feats = int(n_feats*ratio)\n",
    "        if next_n_feats < min_feats:\n",
    "            break\n",
    "        else:\n",
    "            feats = feat_imp.iloc[:next_n_feats].index.tolist()\n",
    "    return archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "dfddc749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 0.8510170453305398\n",
      "359 0.8453643684934198\n",
      "323 0.8502385243538362\n",
      "290 0.8490490614672608\n",
      "261 0.8500854621330383\n",
      "234 0.8499102877340015\n",
      "210 0.8457965610680928\n",
      "189 0.8484138388923924\n",
      "170 0.8534778148802897\n",
      "153 0.8480471213389987\n",
      "137 0.8441390092135992\n",
      "123 0.842383819169478\n",
      "110 0.8490137394163074\n",
      "99 0.846091485834996\n",
      "89 0.8474386056807047\n",
      "80 0.8424834675571269\n",
      "72 0.8428131400326917\n",
      "64 0.8410220535953253\n",
      "57 0.8469696551993485\n",
      "51 0.8450065532455509\n",
      "45 0.8474742149028041\n",
      "40 0.8383338444979731\n"
     ]
    }
   ],
   "source": [
    "lgbm_8 = lgbm_rfe_8(train_x, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "7e9c028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = LGBMClassifier(objective=\"binary\", num_iterations=10**3)\n",
    "x_train_4 = train_x[lgbm_8.iloc[8,2]]\n",
    "model4.fit(x_train_4, train_y)\n",
    "\n",
    "pred_y4 = model4.predict_proba(test[lgbm_8.iloc[8,2]])\n",
    "pred_y4 = pred_y4[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "c008c715",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_all = (pred_y1 + pred_y2 + pred_y3 + pred_y4) * (1/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac8dfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LGBM + Extrees Regressor\n",
    "\n",
    "pred_y_ensemble = (preds_tune)*(0.75) + (pred_all)*(0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24903dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "    \"nerdiness\" : pred_y_ensemble\n",
    "})\n",
    "submission.to_csv('sub_0826.csv', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c86cf41",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb = pd.read_csv('sub_0826_.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dbfc98",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb.rename(columns = {'Unnamed: 0' : 'index'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a4caa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "subb.set_index('index', inplace = True)\n",
    "subb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
